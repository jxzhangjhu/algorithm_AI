{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File la-haute-borne-data-2013-2016.csv does not exist: 'la-haute-borne-data-2013-2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26189fd34d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0mdate_to_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m \u001b[0mturbineData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstTurbineData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWa_c_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m X=np.array([turbineData[:4],\n\u001b[1;32m    384\u001b[0m                    \u001b[0mturbineData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-26189fd34d06>\u001b[0m in \u001b[0;36mfirstTurbineData\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfirstTurbineData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'la-haute-borne-data-2013-2016.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#remove timezone (caused me an hour of pain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File la-haute-borne-data-2013-2016.csv does not exist: 'la-haute-borne-data-2013-2016.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Optimizer:\n",
    "    #USE SAME DEFAULTS AS KERAS ADAM OPTIMIZER\n",
    "    def __init__(self, lr=.1, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=0, decay=0., **kwargs):\n",
    "        \n",
    "        allowed_kwargs = {'clipnorm', 'clipvalue'}\n",
    "        for k in kwargs:\n",
    "            if k not in allowed_kwargs:\n",
    "                raise TypeError('Unexpected keyword argument '\n",
    "                                'passed to optimizer: ' + str(k))\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.iterations = 1\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    def get_ADAM(self, params, grads):\n",
    "\n",
    "        original_shapes = [x.shape for x in params]\n",
    "        params = [x.flatten() for x in params]\n",
    "        grads = [x.flatten() for x in grads]\n",
    "        \n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "        t = self.iterations + 1\n",
    "        lr_t = lr * (np.sqrt(1. - np.power(self.beta_2, t)) /\n",
    "                     (1. - np.power(self.beta_1, t)))\n",
    "\n",
    "        if not hasattr(self, 'ms'):\n",
    "            self.ms = [np.zeros(p.shape) for p in params]\n",
    "            self.vs = [np.zeros(p.shape) for p in params]\n",
    "    \n",
    "        ret = [None] * len(params)\n",
    "        for i, p, g, m, v in zip(range(len(params)), params, grads, self.ms, self.vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * np.square(g)\n",
    "            p_t = p - lr_t * m_t / (np.sqrt(v_t) + self.epsilon)\n",
    "            self.ms[i] = m_t\n",
    "            self.vs[i] = v_t\n",
    "            ret[i] = p_t\n",
    "        self.iterations += 1\n",
    "  \n",
    "        for i in range(len(ret)):\n",
    "            ret[i] = ret[i].reshape(original_shapes[i])\n",
    "\n",
    "        return np.array(ret)\n",
    "\n",
    "\n",
    "    def get_SGD(self, w,p):\n",
    "        for x,y in zip(w,p):\n",
    "                    x+=self.lr*y\n",
    "        return w[0],w[1],w[2],w[3],w[4],w[5],w[6],w[7],w[8],w[9]\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def tanh_derivative(values): \n",
    "    return 1. - values ** 2\n",
    "\n",
    "# createst uniform random array w/ values in [a,b) and shape args\n",
    "def rand_arr(a, b, *args): \n",
    "    np.random.seed(0)\n",
    "    return (np.random.rand(*args) * (b - a) + a)*.1\n",
    "\n",
    "class LstmParam:\n",
    "    def __init__(self, mem_cell_ct, x_dim,optimization):\n",
    "        self.mem_cell_ct = mem_cell_ct\n",
    "        self.x_dim = x_dim\n",
    "        concat_len = x_dim + mem_cell_ct\n",
    "        \n",
    "        self.opt=Optimizer()\n",
    "        self.optimization=optimization\n",
    "\n",
    "        # weight matrices\n",
    "        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n",
    "        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "\n",
    "        # bias terms\n",
    "        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct)\n",
    "\n",
    "\n",
    "        \n",
    "        # diffs (derivative of loss function w.r.t. all parameters)\n",
    "        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.bg_diff = np.zeros(mem_cell_ct) \n",
    "        self.bi_diff = np.zeros(mem_cell_ct) \n",
    "        self.bf_diff = np.zeros(mem_cell_ct) \n",
    "        self.bo_diff = np.zeros(mem_cell_ct) \n",
    "\n",
    "    def apply_diff(self, lr = .1):\n",
    "        if(self.optimization=='adam'):\n",
    "            self.wg=self.opt.get_ADAM(self.wg,self.wg_diff)\n",
    "            self.wi=self.opt.get_ADAM(np.array(self.wi),np.array(self.wi_diff))\n",
    "            self.wf=self.opt.get_ADAM(np.array(self.wf),np.array(self.wf_diff))\n",
    "            self.wo=self.opt.get_ADAM(np.array(self.wo),np.array(self.wo_diff))\n",
    "\n",
    "        else:\n",
    "            #This is the stochastic gradient descent code\n",
    "            self.wg -= lr * self.wg_diff\n",
    "            self.wi -= lr * self.wi_diff\n",
    "            self.wf -= lr * self.wf_diff\n",
    "            self.wo -= lr * self.wo_diff\n",
    "\n",
    "\n",
    "        \n",
    "        self.bg -= lr * self.bg_diff\n",
    "        self.bi -= lr * self.bi_diff\n",
    "        self.bf -= lr * self.bf_diff\n",
    "        self.bo -= lr * self.bo_diff\n",
    "        \n",
    "        # reset diffs to zero\n",
    "        self.wg_diff = np.zeros_like(self.wg)\n",
    "        self.wi_diff = np.zeros_like(self.wi) \n",
    "        self.wf_diff = np.zeros_like(self.wf) \n",
    "        self.wo_diff = np.zeros_like(self.wo) \n",
    "        self.bg_diff = np.zeros_like(self.bg)\n",
    "        self.bi_diff = np.zeros_like(self.bi) \n",
    "        self.bf_diff = np.zeros_like(self.bf) \n",
    "        self.bo_diff = np.zeros_like(self.bo) \n",
    "\n",
    "class LstmState:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.g = np.zeros(mem_cell_ct)\n",
    "        self.i = np.zeros(mem_cell_ct)\n",
    "        self.f = np.zeros(mem_cell_ct)\n",
    "        self.o = np.zeros(mem_cell_ct)\n",
    "        self.s = np.zeros(mem_cell_ct)\n",
    "        self.h = np.zeros(mem_cell_ct)\n",
    "        self.bottom_diff_h = np.zeros_like(self.h)\n",
    "        self.bottom_diff_s = np.zeros_like(self.s)\n",
    "    \n",
    "class LstmNode:\n",
    "    def __init__(self, lstm_param, lstm_state):\n",
    "        # store reference to parameters and to activations\n",
    "        self.state = lstm_state\n",
    "        self.param = lstm_param\n",
    "\n",
    "        # non-recurrent input concatenated with recurrent input\n",
    "        self.xc = None\n",
    "\n",
    "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
    "        # if this is the first lstm node in the network\n",
    "        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n",
    "        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n",
    "        # save data for use in backprop\n",
    "        self.s_prev = s_prev\n",
    "        self.h_prev = h_prev\n",
    "\n",
    "        # concatenate x(t) and h(t-1)\n",
    "        xc = np.hstack((x,  h_prev))\n",
    "        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n",
    "        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n",
    "        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n",
    "        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n",
    "        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n",
    "        self.state.h = self.state.s * self.state.o\n",
    "\n",
    "        self.xc = xc\n",
    "\n",
    "    \n",
    "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
    "        # notice that top_diff_s is carried along the constant error carousel\n",
    "        ds = self.state.o * top_diff_h + top_diff_s\n",
    "        do = self.state.s * top_diff_h\n",
    "        di = self.state.g * ds\n",
    "        dg = self.state.i * ds\n",
    "        df = self.s_prev * ds\n",
    "\n",
    "        # diffs w.r.t. vector inside sigma / tanh function\n",
    "        di_input = sigmoid_derivative(self.state.i) * di \n",
    "        df_input = sigmoid_derivative(self.state.f) * df \n",
    "        do_input = sigmoid_derivative(self.state.o) * do \n",
    "        dg_input = tanh_derivative(self.state.g) * dg\n",
    "\n",
    "        # diffs w.r.t. inputs\n",
    "        self.param.wi_diff += np.outer(di_input, self.xc)\n",
    "        self.param.wf_diff += np.outer(df_input, self.xc)\n",
    "        self.param.wo_diff += np.outer(do_input, self.xc)\n",
    "        self.param.wg_diff += np.outer(dg_input, self.xc)\n",
    "        self.param.bi_diff += di_input\n",
    "        self.param.bf_diff += df_input       \n",
    "        self.param.bo_diff += do_input\n",
    "        self.param.bg_diff += dg_input\n",
    "\n",
    "        #for dparam in [self.param.wi_diff, self.param.wf_diff , self.param.wo_diff, self.param.wg_diff, self.param.bi_diff, self.param.bf_diff, self.param.bo_diff, self.param.bg_diff]:\n",
    "        #    np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "        # compute bottom diff\n",
    "        dxc = np.zeros_like(self.xc)\n",
    "        dxc += np.dot(self.param.wi.T, di_input)\n",
    "        dxc += np.dot(self.param.wf.T, df_input)\n",
    "        dxc += np.dot(self.param.wo.T, do_input)\n",
    "        dxc += np.dot(self.param.wg.T, dg_input)\n",
    "\n",
    "        # save bottom diffs\n",
    "        self.state.bottom_diff_s = ds * self.state.f\n",
    "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
    "\n",
    "class LstmNetwork():\n",
    "    def __init__(self, lstm_param, loss):\n",
    "        self.lstm_param = lstm_param\n",
    "        self.lstm_node_list = []\n",
    "        # input sequence\n",
    "        self.x_list = []\n",
    "        self.loss=loss\n",
    "\n",
    "    def y_list_is(self, y_list, loss_layer):\n",
    "        \"\"\"\n",
    "        Updates diffs by setting target sequence \n",
    "        with corresponding loss layer. \n",
    "        Will *NOT* update parameters.  To update parameters,\n",
    "        call self.lstm_param.apply_diff()\n",
    "        \"\"\"\n",
    "        assert len(y_list) == len(self.x_list)\n",
    "        idx = len(self.x_list) - 1\n",
    "        # first node only gets diffs from label ...\n",
    "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx],self.loss)\n",
    "\n",
    "        diff_h =loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "\n",
    "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
    "        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n",
    "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "        idx -= 1\n",
    "\n",
    "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
    "        ### we also propagate error along constant error carousel using diff_s\n",
    "        while idx >= 0:\n",
    "            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx],self.loss)\n",
    "            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
    "            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
    "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "            idx -= 1 \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def x_list_clear(self):\n",
    "        self.x_list = []\n",
    "\n",
    "    def x_list_add(self, x):\n",
    "        self.x_list.append(x)\n",
    "       # print(self.x_list)\n",
    "        if len(self.x_list) > len(self.lstm_node_list):\n",
    "            # need to add new lstm node, create new state mem\n",
    "            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n",
    "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
    "\n",
    "        # get index of most recent x input\n",
    "        idx = len(self.x_list) - 1\n",
    "        if idx == 0:\n",
    "            # no recurrent inputs yet\n",
    "            self.lstm_node_list[idx].bottom_data_is(x)\n",
    "        else:\n",
    "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
    "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
    "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n",
    "\n",
    "\n",
    "\n",
    "class LossLayer:\n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    MG-Attempted to add in mae loss for comparison, but RMSE and MAE loss performed the same.  \n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def loss(self,pred, label,fn):\n",
    "        if(fn=='mae'):\n",
    "            return LossLayer.loss_mae(pred,label)\n",
    "        else:\n",
    "            return LossLayer.loss_rmse(pred,label)\n",
    "    \n",
    "    # MG added mean absolute error\n",
    "    @classmethod\n",
    "    def loss_mae(self, pred, label):\n",
    "        return (np.abs(pred[0]-label))\n",
    "        #return (pred[0] - label) ** 2\n",
    "    \n",
    "    @classmethod\n",
    "    def loss_rmse(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] =2*(pred[0] - label)\n",
    "        return diff\n",
    "\n",
    "\n",
    "\n",
    "def train(loss, optimization):\n",
    "    mem_cell_ct = 50\n",
    "    x_dim = 4\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim,optimization)\n",
    "    lstm_net = LstmNetwork(lstm_param,loss)\n",
    "    losses=[]\n",
    "    bestLoss=1e5\n",
    "    print(\"Training...\")\n",
    "    for cur_iter in range(100):\n",
    "       \n",
    "        for ind in range(len(Y)):\n",
    "            lstm_net.x_list_add(X[ind])\n",
    "\n",
    "        if(cur_iter%50==0):\n",
    "            print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
    "            print(\"y_pred = [\" +\n",
    "                  \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(Y))]) +\n",
    "                  \"]\", end=\", \")\n",
    "\n",
    "        loss = lstm_net.y_list_is(Y, LossLayer)\n",
    "        losses.append(loss)\n",
    "        if(loss<bestLoss):\n",
    "            best_lstm_net = LstmNetwork(lstm_param,loss)\n",
    "            \n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        \n",
    "        if(cur_iter%50==0):\n",
    "            print(\"loss:\", \"%.3e\" % loss)\n",
    "\n",
    "        lstm_net.x_list_clear()\n",
    "    \n",
    "    for ind in range(len(Y)):\n",
    "        best_lstm_net.x_list_add(X[ind])   \n",
    "    loss = best_lstm_net.y_list_is(Y, LossLayer)\n",
    "    return losses, [ best_lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(Y))],loss\n",
    "\n",
    "\n",
    "\n",
    "def firstTurbineData():\n",
    "\tdf = pd.read_csv('la-haute-borne-data-2013-2016.csv', sep=';')\n",
    "\tdf['Date_time'] = df['Date_time'].astype(str).str[:-6] #remove timezone (caused me an hour of pain)\n",
    "\tdf.Date_time=pd.to_datetime(df['Date_time'])\n",
    "\tdf=df.fillna(method='ffill')\n",
    "\n",
    "\tdf=df.sort_values(by='Date_time')\n",
    "\tdf = df.reset_index()\n",
    "\tturbines=df.Wind_turbine_name.unique()\n",
    "\tprint(\"Turbine name: \"+str(turbines[0]))\n",
    "\tturbineData=df[df['Wind_turbine_name']==turbines[0]]\n",
    "\treturn turbineData\n",
    "\n",
    "\n",
    "def createGraph(losses, title):\n",
    "\tX = np.arange(0,len(losses))\n",
    "\tfigure = plt.figure()\n",
    "\ttick_plot = figure.add_subplot(1, 1, 1)\n",
    "\ttick_plot.plot(X, losses,  color='green', linestyle='-', marker='*' )\n",
    "\tplt.xlabel('Iteration')\n",
    "\tplt.ylabel('Loss')\n",
    "\tplt.title(title)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "date_to_test=datetime.datetime(2016, 1, 1)\n",
    "turbineData=np.sin(firstTurbineData().Wa_c_avg.values)[:10]\n",
    "X=np.array([turbineData[:4],\n",
    "                   turbineData[1:5],\n",
    "                   turbineData[2:6],\n",
    "                   turbineData[3:7],\n",
    "                   turbineData[4:8],\n",
    "                   turbineData[5:9]])\n",
    "Y=np.array([turbineData[4],\n",
    "                   turbineData[5],\n",
    "                   turbineData[6],\n",
    "                   turbineData[7],\n",
    "                   turbineData[8],\n",
    "                   turbineData[9]])\n",
    "\n",
    "\n",
    "losses, predictions,loss=train('rmse','sgd')\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(Y)\n",
    "print(predictions)\n",
    "createGraph(losses,\"SGD Optimization\\nLoss=\"+str(loss))\n",
    "losses, predictions,loss=train('rmse','adam')\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(Y)\n",
    "print(predictions)\n",
    "createGraph(losses,\"Adam Optimization\\nLoss=\"+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
